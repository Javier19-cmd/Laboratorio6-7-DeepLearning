{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primer red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sebas\\AppData\\Local\\Temp\\ipykernel_17364\\4169389186.py:9: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  books_data = pd.read_csv('./archive/Books.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(919824, 2)\n",
      "(919824,)\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_6 (Embedding)     (None, None, 64)          21764288  \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, None, 64)          4160      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, None, 1)           65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 21768513 (83.04 MB)\n",
      "Trainable params: 21768513 (83.04 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      " 3402/22996 [===>..........................] - ETA: 1:19:02 - loss: 14.1680"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the data\n",
    "users_data = pd.read_csv('./archive/Users.csv')\n",
    "books_data = pd.read_csv('./archive/Books.csv')\n",
    "ratings_data = pd.read_csv('./archive/Ratings.csv')\n",
    "\n",
    "ratings_data['ISBN'] = ratings_data['ISBN'].str.rstrip('X')\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "ratings_data['ISBN'] = label_encoder.fit_transform(ratings_data['ISBN'])\n",
    "\n",
    "# print(users_data.shape)\n",
    "# print(books_data.shape)\n",
    "# print(ratings_data.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(ratings_data[[\"User-ID\", \"ISBN\"]], ratings_data['Book-Rating'], test_size=0.2, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(input_dim=len(ratings_data['ISBN'].unique()) + 1, output_dim=64),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "\n",
    "# Compilando el modelo.\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, time, re\n",
    "import pickle, gzip, datetime\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, mean_squared_error\n",
    "#import lightgbm as lgb\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Activation, Dense, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization, Input, Lambda\n",
    "from tensorflow.keras.layers import Embedding, Flatten, dot\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.losses import mse, binary_crossentropy\n",
    "\n",
    "\n",
    "ratingDF = pd.read_csv('ratings.csv')\n",
    "\n",
    "\n",
    "ratingDF.userId = ratingDF.userId.astype(str).astype(int)\n",
    "ratingDF.movieId = ratingDF.movieId.astype(str).astype(int)\n",
    "ratingDF.rating = ratingDF.rating.astype(str).astype(float)\n",
    "ratingDF.timestamp = ratingDF.timestamp.apply(lambda x: now.strftime(\"%m/%d/%Y, %H:%M:%S\"))\n",
    "\n",
    "n_users = ratingDF.userId.unique().shape[0]\n",
    "n_movies = ratingDF.movieId.unique().shape[0]\n",
    "n_ratings = len(ratingDF)\n",
    "avg_ratings_per_user = n_ratings/n_users\n",
    "\n",
    "print('Number of unique users: ', n_users)\n",
    "print('Number of unique movies: ', n_movies)\n",
    "print('Number of total ratings: ', n_ratings)\n",
    "print('Average number of ratings per user: ', avg_ratings_per_user)\n",
    "\n",
    "movieIndex = ratingDF.groupby(\"movieId\").count().sort_values(by= \\\n",
    "\"rating\",ascending=False)[0:1000].index\n",
    "ratingDFX2 = ratingDF[ratingDF.movieId.isin(movieIndex)]\n",
    "ratingDFX2.count()\n",
    "\n",
    "userIndex = ratingDFX2.groupby(\"userId\").count().sort_values(by= \\\n",
    "\"rating\",ascending=False).sample(n=1000, random_state=2018).index\n",
    "ratingDFX3 = ratingDFX2[ratingDFX2.userId.isin(userIndex)]\n",
    "ratingDFX3.count()\n",
    "\n",
    "movies = ratingDFX3.movieId.unique()\n",
    "moviesDF = pd.DataFrame(data=movies,columns=['originalMovieId'])\n",
    "moviesDF['newMovieId'] = moviesDF.index+1\n",
    "\n",
    "users = ratingDFX3.userId.unique()\n",
    "usersDF = pd.DataFrame(data=users,columns=['originalUserId'])\n",
    "usersDF['newUserId'] = usersDF.index+1\n",
    "\n",
    "ratingDFX3 = ratingDFX3.merge(moviesDF,left_on='movieId', \\\n",
    "right_on='originalMovieId')\n",
    "ratingDFX3.drop(labels='originalMovieId', axis=1, inplace=True)\n",
    "ratingDFX3 = ratingDFX3.merge(usersDF,left_on='userId', \\\n",
    "right_on='originalUserId')\n",
    "ratingDFX3.drop(labels='originalUserId', axis=1, inplace=True)\n",
    "\n",
    "n_users = ratingDFX3.userId.unique().shape[0]\n",
    "n_movies = ratingDFX3.movieId.unique().shape[0]\n",
    "n_ratings = len(ratingDFX3)\n",
    "avg_ratings_per_user = n_ratings/n_users\n",
    "\n",
    "print('Number of unique users: ', n_users)\n",
    "print('Number of unique movies: ', n_movies)\n",
    "print('Number of total ratings: ', n_ratings)\n",
    "print('Average number of ratings per user: ', avg_ratings_per_user)\n",
    "\n",
    "X_train, X_test = train_test_split(ratingDFX3,\n",
    "test_size=0.10, shuffle=True, random_state=2018)\n",
    "X_validation, X_test = train_test_split(X_test,\n",
    "test_size=0.50, shuffle=True, random_state=2018)\n",
    "\n",
    "print('Shape of train set:', X_train.shape)\n",
    "print('Shape of validation set:',X_validation.shape)\n",
    "print('Shape of test set: ',X_test.shape)\n",
    "\n",
    "print('Size of train set:', X_train.size)\n",
    "print('Size of validation set:',X_validation.size)\n",
    "print('Size of test set: ',X_test.size)\n",
    "\n",
    "# Generate ratings matrix for train\n",
    "ratings_train = np.zeros((n_users, n_movies))\n",
    "for row in X_train.itertuples():\n",
    "    ratings_train[row[6]-1, row[5]-1] = row[3]\n",
    "    \n",
    "sparsity = float(len(ratings_train.nonzero()[0]))\n",
    "sparsity /= (ratings_train.shape[0] * ratings_train.shape[1])\n",
    "sparsity *= 100\n",
    "print('Sparsity: {:4.2f}%'.format(sparsity))\n",
    "\n",
    "# Generate ratings matrix for validation\n",
    "ratings_validation = np.zeros((n_users, n_movies))\n",
    "for row in X_validation.itertuples():\n",
    "    ratings_validation[row[6]-1, row[5]-1] = row[3]\n",
    "    \n",
    "# Generate ratings matrix for test\n",
    "ratings_test = np.zeros((n_users, n_movies))\n",
    "for row in X_test.itertuples():\n",
    "    ratings_test[row[6]-1, row[5]-1] = row[3]\n",
    "\n",
    "n_latent_factors = 1\n",
    "user_input = Input(shape=[1], name='user')\n",
    "user_embedding = Embedding(input_dim=n_users + 1, output_dim=n_latent_factors,\n",
    "name='user_embedding')(user_input)\n",
    "user_vec = Flatten(name='flatten_users')(user_embedding)\n",
    "movie_input = Input(shape=[1], name='movie')\n",
    "movie_embedding = Embedding(input_dim=n_movies + 1,\n",
    "output_dim=n_latent_factors,\n",
    "name='movie_embedding')(movie_input)\n",
    "movie_vec = Flatten(name='flatten_movies')(movie_embedding)\n",
    "product = dot([movie_vec, user_vec], axes=1)\n",
    "model = Model(inputs=[user_input, movie_input], outputs=product)\n",
    "model.compile('adam', 'mean_squared_error')\n",
    "\n",
    "X_train\n",
    "\n",
    "history = model.fit(x=[X_train.newUserId, X_train.newMovieId],\n",
    "                    y=X_train.rating, epochs=20,\n",
    "                    validation_data=([X_validation.newUserId,\n",
    "                                      X_validation.newMovieId], X_validation.rating),\n",
    "                    verbose=1)\n",
    "\n",
    "pd.Series(history.history['val_loss'][10:]).plot(logy=False)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Validation Error\")\n",
    "print('Minimum MSE: ', min(history.history['val_loss']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
